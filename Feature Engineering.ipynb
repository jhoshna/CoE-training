{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a678bca-0c6f-4755-ad4a-1562a75287ab",
   "metadata": {},
   "source": [
    "**What is Feature Engineering?**\n",
    " \n",
    "            Feature engineering is the process of creating new features or modifying existing ones to improve the performance of machine learning models. It involves techniques like feature extraction, transformation, encoding, and scaling to make data more useful for predictions.\n",
    " \n",
    "**Why Do We Need Feature Engineering?**\n",
    " \n",
    "1.**Improves Model Performance** – Good features help models make better predictions.\n",
    " \n",
    "2.**Reduces Overfitting** – Helps eliminate noise and irrelevant data.\n",
    " \n",
    "3.**Handles Missing Data** – Creates meaningful replacements for missing values.\n",
    " \n",
    "4.**Enables Better Interpretability** – Makes features more understandable and useful.\n",
    "\n",
    "5.**Reduces Dimensionality** – Helps remove unnecessary data points, making the model efficient.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41095db8-7479-4a67-b9c4-3000669a124a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TransactionDate  DayOfWeek  Hour  IsWeekend\n",
      "0 2025-02-05 14:30:00          2    14          0\n",
      "1 2025-02-06 18:45:00          3    18          0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#sample dataset\n",
    "df=pd.DataFrame({'TransactionDate':pd.to_datetime(['2025-02-05 14:30:00','2025-02-06 18:45:00'])})\n",
    "# Extract date-relted features\n",
    "df['DayOfWeek']=df['TransactionDate'].dt.dayofweek\n",
    "df['Hour']=df['TransactionDate'].dt.hour\n",
    "df['IsWeekend']=df['DayOfWeek'].apply(lambda x: 1 if x>=5 else 0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0e4233f-a1e6-49db-b763-0d784be78470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  AvgTransactionAmount\n",
      "0     101                 500.0\n",
      "1     102                 650.0\n",
      "2     103                 700.0\n"
     ]
    }
   ],
   "source": [
    "#Aggregrated Features\n",
    "#fIND AVERAGE TRANSACTION AMOUNT PER USER:\n",
    "df_transaction = pd.DataFrame({\n",
    "    'UserID':[101,102,103,102],\n",
    "    'TransactionAmount':[500,300,700,1000]\n",
    "})\n",
    "df_user_avg = df_transaction.groupby('UserID')['TransactionAmount'].mean().reset_index()\n",
    "df_user_avg.rename(columns={'TransactionAmount' : 'AvgTransactionAmount'},inplace=True)\n",
    "print(df_user_avg)\n",
    "#why? Identifies high-value customers and spending patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c27cdf2-25ee-47e6-a9b0-e0051c24e59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductCategory_Clothing  ProductCategory_Electronics  \\\n",
      "0                       0.0                          1.0   \n",
      "1                       1.0                          0.0   \n",
      "2                       1.0                          0.0   \n",
      "3                       0.0                          0.0   \n",
      "\n",
      "   ProductCategory_Grocery  \n",
      "0                      0.0  \n",
      "1                      0.0  \n",
      "2                      0.0  \n",
      "3                      1.0  \n"
     ]
    }
   ],
   "source": [
    "#Encoding Categorical variables\n",
    "#Convert productcategory (Electronics,clothing) into numerical foem:\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df=pd.DataFrame({'ProductCategory':['Electronics','Clothing','Clothing','Grocery']})\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(df[['ProductCategory']])\n",
    "\n",
    "df_encoded = pd.DataFrame(encoded_features,columns=encoder.get_feature_names_out())\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de945ad2-c42a-4554-97e9-34a5f7e66af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionAmount  LogTransactionAmount\n",
      "0                100              4.615121\n",
      "1                200              5.303305\n",
      "2               5000              8.517393\n",
      "3              10000              9.210440\n",
      "4              20000              9.903538\n"
     ]
    }
   ],
   "source": [
    "#Log Transformation for skewed Data\n",
    "#If TransformationAmount has outliers,apply log transformation:\n",
    "import numpy as np\n",
    "\n",
    "df=pd.DataFrame({'TransactionAmount': [100,200,5000,10000,20000]})\n",
    "df['LogTransactionAmount'] = np.log1p(df['TransactionAmount'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6c294f5-b7e8-4bbb-899d-3b9969d20907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionAmount  LogTransactionAmount  NormalizedTransactionAmount  \\\n",
      "0                100              4.615121                     0.000000   \n",
      "1                200              5.303305                     0.005025   \n",
      "2               5000              8.517393                     0.246231   \n",
      "3              10000              9.210440                     0.497487   \n",
      "4              20000              9.903538                     1.000000   \n",
      "\n",
      "   StandardizedTransactionAmount  \n",
      "0                      -0.937070  \n",
      "1                      -0.923606  \n",
      "2                      -0.277351  \n",
      "3                       0.395831  \n",
      "4                       1.742196  \n"
     ]
    }
   ],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['NormalizedTransactionAmount'] = scaler.fit_transform(df[['TransactionAmount']])\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "df['StandardizedTransactionAmount'] = standard_scaler.fit_transform(df[['TransactionAmount']])\n",
    "print(df)\n",
    "\n",
    "#Why? Ensures all features have the same scale,preventing bias in ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d89825-d26b-446b-bdd5-35464286d356",
   "metadata": {},
   "source": [
    "**Final Summary of Feature Engineering & Imbalanced Data Handling**\n",
    " \n",
    "Feature Extraction : Extract new insights from raw data (e.g., Hour, DayOfWeek)\n",
    " \n",
    "Aggregated Features : Calculate meaningful statistics (e.g., AvgTransactionAmountPerUser)\n",
    " \n",
    "Encoding : Convert categorical variables into numerical (One-Hot Encoding)\n",
    " \n",
    "Log Transformation : Reduce skewness in data distribution\n",
    " \n",
    "Feature Scaling : Normalize numerical features for better model performance\n",
    " \n",
    "Downsampling: Reduce the size of the majority class\n",
    " \n",
    "Upsampling : Increase the size of the minority class\n",
    " \n",
    "SMOTE(Synthetic Minority Over-sampling Technique) : Generate synthetic samples for the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2a518-d1e7-4967-8e9e-08a2b897de50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
